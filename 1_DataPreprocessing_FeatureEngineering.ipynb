{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as snsb\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Importing FINRA pdf files\n",
    "\n",
    "FINRA operates the largest securities dispute resolution forum in the United States, and has extensive experience in providing a fair, efficient and effective venue to handle a securities-related dispute.\n",
    "\n",
    "All cases related to Arbitraion and Mediation can be found online and can be scraped.\n",
    "\n",
    "### Scraping FINRA pdf case files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    tab_df, = pd.read_html('https://www.finra.org/arbitration-and-mediation/arbitration-awards-online?page=\"+str(i)')\n",
    "    tab_df.to_csv(\"table.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the cleaned data set\n",
    "m_df= pd.read_csv('data/finra_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forming groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges_list =[]\n",
    "for line in open('data/list_judges.txt').readlines():\n",
    "    judges_list.append(line.replace(\"\\n\",\"\"))\n",
    "    \n",
    "## NAR list\n",
    "nar_list =[]\n",
    "for line in open('data/nar_list.txt').readlines():\n",
    "    nar_list.append(line.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_member_lawyer(row):\n",
    "    \n",
    "    member_lawyer_flag= False\n",
    "    claimant_reps = row['Claimant_Reps']\n",
    "    claimant_reps_list = str(claimant_reps).split(\",\")\n",
    "    for c_i in claimant_reps_list:\n",
    "        ## check if any of the claimants in the judges list\n",
    "        for judge in judges_list:\n",
    "            if Levenshtein.ratio(c_i,judge) >= 0.90:\n",
    "                member_lawyer_flag= True\n",
    "    ## \n",
    "    respondent_reps = row['Respondent_Reps']\n",
    "    respondent_reps_list = str(respondent_reps).split(\",\")\n",
    "    for r_i in respondent_reps_list:\n",
    "        ## check if any of the claimants in the judges list\n",
    "        for judge in judges_list:\n",
    "            if Levenshtein.ratio(r_i,judge) >= 0.90:\n",
    "                member_lawyer_flag= True\n",
    "    return member_lawyer_flag\n",
    "\n",
    "m_df['is_present_in_judge_list'] = m_df.apply(check_member_lawyer,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_esq(row):\n",
    "    esq_flag= False\n",
    "    file_path = '/data/raw/sentences_finra_forum/'+ row['file_id']\n",
    "    f = open(file_path,'r').read().lower()\n",
    "    if ('esq' in f):\n",
    "        esq_flag = True\n",
    "    return esq_flag\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "m_df['is_esq'] = m_df.apply(check_esq,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_NAR(row):\n",
    "    \n",
    "    nar_flag= False\n",
    "    claimant_reps = row['Claimant_Reps']\n",
    "    claimant_reps_list = str(claimant_reps).split(\",\")\n",
    "    for c_i in claimant_reps_list:\n",
    "        ## check if any of the claimants in the judges list\n",
    "        for judge in nar_list:\n",
    "            if Levenshtein.ratio(c_i,judge) >= 0.90:\n",
    "                nar_flag= True\n",
    "    ## \n",
    "    respondent_reps = row['Respondent_Reps']\n",
    "    respondent_reps_list = str(respondent_reps).split(\",\")\n",
    "    for r_i in respondent_reps_list:\n",
    "        ## check if any of the claimants in the judges list\n",
    "        for judge in nar_list:\n",
    "            if Levenshtein.ratio(r_i,judge) >= 0.90:\n",
    "                nar_flag= True\n",
    "    return nar_flag\n",
    "\n",
    "m_df['is_present_in_nar_list'] = m_df.apply(check_member_lawyer,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df['new_group'] = None\n",
    "for i in m_df.index:\n",
    "    if ((m_df.loc[i,'is_claimant_matches_claimant_reps']==True) & (m_df.loc[i,'count_no_of_claimant_reps']==1)):\n",
    "        m_df.loc[i,'new_group'] = 'Group 1: Pro Se'\n",
    "    elif ((m_df.loc[i,'is_claimant_matches_claimant_reps']==False) \\\n",
    "          & (m_df.loc[i,'count_no_of_claimant_reps']==1)\\\n",
    "         & (m_df.loc[i,'is_present_in_nar_list']==True)):\n",
    "        m_df.loc[i,'new_group'] = 'Group 2: One Non-Attorney'\n",
    "    elif ((m_df.loc[i,'is_claimant_matches_claimant_reps']==False) \\\n",
    "          & (m_df.loc[i,'count_no_of_claimant_reps']==1)\\\n",
    "          & (m_df.loc[i,'is_present_in_nar_list']==False)\\\n",
    "         & (m_df.loc[i,'is_esq']==True)):\n",
    "        m_df.loc[i,'new_group'] = 'Group 3: One Attorney'\n",
    "    elif (m_df.loc[i,'count_no_of_claimant_reps']>1):\n",
    "        m_df.loc[i,'new_group'] = 'Group 4: Multiple Representatives'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Regions from States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df['state'] = m_df['Hearing_Site'].apply(lambda x:str(x).split(\",\")[-1].replace(\" \",\"\"))\n",
    "region_df = pd.read_csv('data/raw/state_regions.csv')\n",
    "\n",
    "m_df = pd.merge(m_df,region_df, left_on ='state',right_on='State Code',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning into Claim Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df= pd.read_excel('claims.xlsx')\n",
    "claim_df = claim_df[['AwardID','Claim_Type']]\n",
    "claim_df = claim_df.drop_duplicates(subset=['AwardID', 'Claim_Type'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df = pd.merge(m_df,claim_df, on='AwardID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_claims(row):\n",
    "    claim_type = str(row['Claim_Type'])\n",
    "    str_claims = claim_type.replace(\"[\",\"\").replace('\"','').replace(\"'\",\"\").replace(\"and\",\" \").replace(\"  \",\" \").replace(\"]\",\"\").lower().strip()\n",
    "    claim_type = str_claims.split(\",\")\n",
    "    claim_type = [cl.strip() for cl in claim_type]\n",
    "    return claim_type\n",
    "\n",
    "\n",
    "m_df['Claim_Type_cleaned'] = m_df.apply(clean_claims,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_dict = {'Claim Type 1: Breach of Contract,Breach of Implied Contract':['breach of contract',\\\n",
    "'breach of the covenant of good faith fair dealing',\\\n",
    "'breach of contract unjust enrichment',\\\n",
    "'breach of implied covenant of good faith fair dealing',\\\n",
    "'breach of the implied covenant of good faith fair dealing',\\\n",
    "'breach of covenant of good faith fair dealing',\\\n",
    "'claimant asserted the cause of action of breach of contract',\\\n",
    "'breach of implied contract',\\\n",
    "'breach of written contract',\\\n",
    "'tortious interference',\\\n",
    "'tortious interference with contract',\\\n",
    "'breach of duty of good faith fair dealing'],\\\n",
    "'Claim Type 2: QuasiContractual Claims':['promissory estoppel',\\\n",
    "'quantum meruit',\\\n",
    "'money had received'],\n",
    "'Claim Type 3: Breach of Fiduciary Duty':['breach of fiduciary duty',\\\n",
    "'breach of fiduciary duties'],\\\n",
    "'Claim Type 4: Negligence':['negligence',\\\n",
    "'gross negligence',\\\n",
    "'negligence gross negligence'],\\\n",
    "'Claim Type 5: Failure to Supervise/Negligent Supervision':['failure to supervise',\\\n",
    "'negligent supervision',\\\n",
    "'respondeat superior',\\\n",
    "'control person liability',\\\n",
    "'professional negligence',\\\n",
    "'vicarious liability',\\\n",
    "'failure to supen ise',\\\n",
    "'negligent hiring',\\\n",
    "'failure to supervise control',\\\n",
    "'negligent supen ision'],\\\n",
    "'Claim Type 6: Fraud':['fraud',\\\n",
    "'common law fraud',\\\n",
    "'fraudulent inducement',\\\n",
    "'constructive fraud',\\\n",
    "'fraud in the inducement',\\\n",
    "'securities fraud',\\\n",
    "'fraud deceit',\\\n",
    "'deceit',\\\n",
    "'manipulation'],\\\n",
    "'Claim Type 7: Unjust Enrichment':['unjust enrichment'],\\\n",
    "'Claim Type 8: Suitability or Unsuitability':['unsuitability',\\\n",
    "'suitability',\\\n",
    "'unsuitable investments',\\\n",
    "'unsuitabiiity'],\\\n",
    "'Claim Type 9: Misrepresentation':['negligent misrepresentation',\\\n",
    "'misrepresentation',\\\n",
    "'misrepresentations',\\\n",
    "'misrepresentations omissions',\\\n",
    "'fraudulent misrepresentation',\\\n",
    "'omissions',\\\n",
    "'omission of facts'],\\\n",
    "'Claim Type 10: Unauthorized Trading':['unauthorized trading',\\\n",
    "'unauthorized transactions'],\\\n",
    "'Claim Type 11: Churning':['churning',\\\n",
    "'excessive trading'],\\\n",
    "'Claim Type 12: Failure to Execute':['failure to execute'],\\\n",
    "'Claim Type 13: Breach of Promissory Note':['breach of promissory note',\\\n",
    "'breach of promissory notes',\\\n",
    "'note',\\\n",
    "'claimant asserted the cause of action of breach of promissory note',\\\n",
    "'the note',\\\n",
    "'breach of promissory note unjust enrichment',\\\n",
    "'note two',\\\n",
    "'note one',\\\n",
    "'breach of promissory note dated november'],\\\n",
    "'Claim Type 14: Conversion 1':['conversion'],\\\n",
    "'Claim Type 15: Violation of Securities Laws/Regulations':['violation of finra rules',\\\n",
    "'violation of finra rule',\\\n",
    "'violations of federal securities laws',\\\n",
    "'violation of state federal securities laws',\\\n",
    "'violation of the florida securities investor protection act',\\\n",
    "'violation of federal securities laws'],\\\n",
    "'Claim Type 16: Employment Related Claims':['wrongful termination',\\\n",
    "'breach of employment contract',\\\n",
    "'misappropriation of trade secrets',\\\n",
    "'constructive discharge',\\\n",
    "'violation of new york labor law',\\\n",
    "'breach of duty of loyalty',\\\n",
    "'tortious interference with business relationships',\\\n",
    "'breach of employment agreement'],\\\n",
    "'Claim Type 17: Other':['defamation',\\\n",
    "'unfair competition',\\\n",
    "'indemnification',\\\n",
    "'intentional infliction of emotional distress',\\\n",
    "'elder abuse']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_claims(row):\n",
    "    claims_present =[]\n",
    "    all_claims = row['Claim_Type_cleaned']\n",
    "    for cl in all_claims:\n",
    "        for k,v in claim_dict.items():\n",
    "            for val in v:\n",
    "                if Levenshtein.ratio(cl,val) >= 0.95:\n",
    "                    claims_present.append(k)\n",
    "    return claims_present\n",
    "\n",
    "m_df['claim_categories'] = m_df.apply(categorize_claims,axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in claim_dict.keys():\n",
    "    m_df[col] = None\n",
    "\n",
    "for i in m_df.index:\n",
    "    if (i%1000==0):\n",
    "        print (i)\n",
    "    all_claims = m_df.loc[i,'claim_categories']\n",
    "    for col in claim_dict.keys():\n",
    "        if col in all_claims:\n",
    "            m_df.loc[i,col] = 1\n",
    "        else:\n",
    "            m_df.loc[i,col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Getting Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = m_df[['AwardID','new_group','Region','Claim Type 1: Breach of Contract,Breach of Implied Contract',\\\n",
    "       'Claim Type 2: QuasiContractual Claims',\\\n",
    "       'Claim Type 3: Breach of Fiduciary Duty', 'Claim Type 4: Negligence',\\\n",
    "       'Claim Type 5: Failure to Supervise/Negligent Supervision',\\\n",
    "       'Claim Type 6: Fraud', 'Claim Type 7: Unjust Enrichment',\\\n",
    "       'Claim Type 8: Suitability or Unsuitability',\\\n",
    "       'Claim Type 9: Misrepresentation',\\\n",
    "       'Claim Type 10: Unauthorized Trading', 'Claim Type 11: Churning',\\\n",
    "       'Claim Type 12: Failure to Execute',\\\n",
    "       'Claim Type 13: Breach of Promissory Note',\\\n",
    "       'Claim Type 14: Conversion 1',\\\n",
    "       'Claim Type 15: Violation of Securities Laws/Regulations',\\\n",
    "       'Claim Type 16: Employment Related Claims', 'Claim Type 17: Other','loser']]\n",
    "df1 = df1.drop_duplicates(keep=False)\n",
    "df2 = df2[['AwardID','loc','AWARD-claims denied','expungement','claimant type']]\n",
    "df2 = df2.drop_duplicates(keep=False)\n",
    "df = pd.merge(df1,df2, on ='AwardID').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['winner'] = 'Respondent'\n",
    "for i in df.index:\n",
    "    df_loser = df.loc[i,'loser']\n",
    "    if df_loser=='Respondent':\n",
    "        df.loc[i,'winner'] = 'Claimant'\n",
    "    elif (df.loc[i,'AWARD-claims denied']==0.0):\n",
    "        df.loc[i,'winner'] = 'Claimant'\n",
    "df.to_csv('data/master_nov_26_20_41.csv')       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
